
Architecture for a "real" compiler:


input stream (chars)

    |
    |
    v

Lexical analyzer (1)

    |
    | tokens
    v

Syntax analyzer (2)

    |
    | syntax tree
    v

Semantic analyzer (3)

    |
    | syntax tree maybe with more info attached
    v

Intermediate code generator (4)

    |
    | intermediate representation
    v

General optimizer (5)

    |
    | intermediate representation
    v

Target code generation (6)

    |
    | target code
    v

Target specific optimizer (7)

    |
    | target code
    v

target code


More discussion of the seven pieces


------------------------------------------------------------
(1) Lexical analyzer aka scanner aka lexer
------------------------------------------------------------

  * convert input program from stream of characters
    into a stream of "tokens"

  * a token is an abstract name or ID plus zero or more attributes
    number, and "what" attributes depend on the token

Example:
    reading a number might generate a token
        <NUMBER, 37>
    reading an operator might generate a token
        <PLUS>

A "lexeme" is a meaningful sequence of characters that produced the token.

example:

  372 + /* multiply these two first */  14 * 3

Tokens:
  <NUMBER, 372>     "372" is the lexeme
  <PLUS>            "+"   is the lexeme
  <NUMBER, 14>      "14"  is the lexeme
  <STAR>            "*"   is the lexeme
  <NUMBER, 3>       "3"   is the lexeme


More fun stuff handled by the lexer maybe?

  * discard white space, comments

  * #include directives
    (switch into the file, and start scanning tokens)

  * #ifdefs and all of the preprocessor


#ifdef MAC_OS

  some code here

#endif


------------------------------------------------------------
(2) Syntax analyzer
------------------------------------------------------------
Aka parser

 * read tokens and create some intermediate representation
   that depicts grammatical structure of the token stream

  * check for and report syntax errors
    3 + + 5

  * Intermediate reps:
    typically a syntax/parse tree

  * is capable of, but might not, build the parse tree


Example:

    37 + 5 + 14 * 3 +

This is lexically correct but not grammatically correct.


------------------------------------------------------------
(3) Semantic analyzer
------------------------------------------------------------

"Checks the source program for semantic consistency within
 the language definition."

For example in C

typedef struct {
  int a;
  int b;
} pair;

int main()
{
  int x = 3;
  pair y;

  y = x;    // this is a type error

  y = z;    // where was z defined?

  foo(x, 4);
}

We'll need an internal data structure to keep track of
  * which identifiers were declared
  * what their types are
  * what functions?  What are their parameters?


All this goes in the "Symbol Table".


------------------------------------------------------------
(4) Intermediate code generator
------------------------------------------------------------

* Most compilers don't generate target code directly

* Instead generates "intermediate code"

* Think of this as "simplified low level code"

* Properties of intermediate code

  (1) "easy" to generate from syntax tree after semantic analysis
  (2) "easy" to produce target code from the intermediate

We will discuss this more later but notice

 + we could write an intepreter for the intermediate code
   to run and test it

 + this makes it easier to add different target code generators
   for the same compiler / compiler family


------------------------------------------------------------
(5) general optimizer
------------------------------------------------------------

* This phase tries to optimize the intermediate code

  + usually want "faster" code but
    could want "smaller" code
    or "power consumption"

* Graph analysis on intermediate code

  + detect unreachable code
  + adjust code layout to avoid jumps

------------------------------------------------------------
(6) target code generator
------------------------------------------------------------

* generate target code from "optimized" intermediate code

* some tricky things here

  + instruction selection (each intermediate code "instruction"
    may require one or more target code instructions)

  + efficient register allocation

  + where are local vars / global vars / parameters stored?

    info will be added to the symbol table

------------------------------------------------------------
(7) target optimizations
------------------------------------------------------------

* target code specific optimizations
  (could be CPU specific)



======================================================================
======================================================================
Compiler "passes" vs "phases"

* Can view each of the 7 steps as a phase of the compiler.

* contiguous phases can be grouped into "passes"

  + each "pass" reads an input file,
    processes,
    writes an output file.

For example:

  + pass 1: input: source, output: intermediate code
    lexer, parser, semantic analyzer, intermediate code gen

  + pass 2: input and output: intermediate code
    intermediate optimizer

  + pass 3: input: intermediate, output: target
    target generator and optimizer


Why?

  New input language: pass 1 changes

  New target machine: pass 3 changes


